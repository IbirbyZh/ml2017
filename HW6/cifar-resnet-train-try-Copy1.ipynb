{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR Conv Net\n",
    "\n",
    "И так, в этом ноутбуке Вы сделаете превую в своей жизни сверточную сеть! На сложном датасете. Cкачайте его кстати, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!mkdir cifar10\n",
    "!curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz -C cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cifar import load_CIFAR10\n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#norm it\n",
    "X_train /= np.float32(255.)\n",
    "X_test /= np.float32(255.)\n",
    "mean = X_train.mean(0)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "# add flipped data\n",
    "X_train_flip = X_train[:,:,:,::-1]\n",
    "y_train_flip = y_train\n",
    "X_train = np.concatenate((X_train,X_train_flip),axis=0)\n",
    "y_train = np.concatenate((y_train,y_train_flip),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">First of all -- Checking Questions</h1> \n",
    "\n",
    "**Вопрос 1**: Чем отличаются современные сверточные сети от сетей 5 летней давности?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 2**: Какие неприятности могут возникнуть во время обучения современных нейросетей?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "\n",
    "**Вопрос 3**: У вас есть очень маленький датасет из 100 картинок, классификация, но вы очень хотите использовать нейросеть, какие неприятности вас ждут и как их решить? что делать если первый вариант  решения не заработает?\n",
    "\n",
    "<Ответ>\n",
    "\n",
    "**Вопрос 4**: Как сделать стайл трансфер для музыки? oO\n",
    "\n",
    "<Ответ>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:04.0)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import *\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Соберите нейронку: \n",
    "- Many times x (Conv+Pool)\n",
    "- Many small convolutions like 3x3\n",
    "- Batch Norm \n",
    "- Residual Connection\n",
    "- Data Augmentation \n",
    "- Learning rate Schedule \n",
    "- ...\n",
    "\n",
    "### Для вдохновения \n",
    "- http://torch.ch/blog/2015/07/30/cifar.html\n",
    "- https://github.com/szagoruyko/wide-residual-networks \n",
    "\n",
    "### Самое интересное\n",
    "- Для сдачи задания нужно набрать на точность тесте > **92.5**% (это займет много времени, торопитесь :) )\n",
    "- Для получения бонусных баллов > **95.0**%\n",
    "- Будет очень хорошо если вы придумаете свою архитектуру или сможете обучить что-то из вышеперечисленного :)\n",
    "- А для обучения всего этого добра вам будет куда удобнее использовать GPU на Amazon \n",
    "    - Инструкция https://github.com/persiyanov/ml-mipt/tree/master/amazon-howto \n",
    "    - Вам помогут tmux, CuDNN, ssh tunnel, nvidia-smi, ... \n",
    "    - Have fun :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from resent_git import build_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_cnn(input_var=input_X, n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with np.load('pre_trained/cifar_model_n9.npz') as f:\n",
    "     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values(net, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = lasagne.layers.get_output(net)\n",
    "all_weights = lasagne.layers.get_all_params(net, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "print len(all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_SCHEDULE = {\n",
    "    0: 0.1,\n",
    "    40: 0.01,\n",
    "    60: 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_penalty = lasagne.regularization.regularize_layer_params(lasagne.layers.get_all_layers(net), \n",
    "                                                            lasagne.regularization.l2) * 0.0001\n",
    "loss = lasagne.objectives.categorical_crossentropy(y_predicted, target_y).mean() + l2_penalty\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted, target_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_r = theano.shared(lasagne.utils.floatX(LR_SCHEDULE[0]))\n",
    "train_fun = theano.function([input_X,target_y],[loss, accuracy], \n",
    "                            updates=lasagne.updates.momentum(loss, all_weights, \n",
    "                                                        learning_rate=l_r),\n",
    "                            allow_input_downcast=True)\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вот и всё, пошли её учить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False, augment=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        if augment:\n",
    "            padded = np.pad(inputs[excerpt],((0,0),(0,0),(4,4),(4,4)),mode='constant')\n",
    "            random_cropped = np.zeros(inputs[excerpt].shape, dtype=np.float32)\n",
    "            crops = np.random.randint(0,high=9,size=(batchsize,2))\n",
    "            for r in range(batchsize):\n",
    "                random_cropped[r,:,:,:] = padded[r,:,crops[r,0]:(crops[r,0]+32),crops[r,1]:(crops[r,1]+32)]\n",
    "            inp_exc = random_cropped\n",
    "        else:\n",
    "            inp_exc = inputs[excerpt]\n",
    "\n",
    "        yield inp_exc, targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 82 took 250.384s\n",
      "  training loss (in-iteration):\t\t2.493403\n",
      "  train accuracy:\t\t31.69 %\n",
      "  validation accuracy:\t\t48.98 %\n",
      "Epoch 2 of 82 took 250.259s\n",
      "  training loss (in-iteration):\t\t1.730353\n",
      "  train accuracy:\t\t54.53 %\n",
      "  validation accuracy:\t\t64.74 %\n",
      "Epoch 3 of 82 took 250.426s\n",
      "  training loss (in-iteration):\t\t1.305190\n",
      "  train accuracy:\t\t68.36 %\n",
      "  validation accuracy:\t\t72.74 %\n",
      "Epoch 4 of 82 took 249.958s\n",
      "  training loss (in-iteration):\t\t1.087197\n",
      "  train accuracy:\t\t74.46 %\n",
      "  validation accuracy:\t\t76.46 %\n",
      "Epoch 5 of 82 took 250.206s\n",
      "  training loss (in-iteration):\t\t0.963387\n",
      "  train accuracy:\t\t77.83 %\n",
      "  validation accuracy:\t\t78.76 %\n",
      "Epoch 6 of 82 took 250.463s\n",
      "  training loss (in-iteration):\t\t0.880794\n",
      "  train accuracy:\t\t79.95 %\n",
      "  validation accuracy:\t\t80.68 %\n",
      "Epoch 7 of 82 took 250.266s\n",
      "  training loss (in-iteration):\t\t0.812106\n",
      "  train accuracy:\t\t81.83 %\n",
      "  validation accuracy:\t\t82.01 %\n",
      "Epoch 8 of 82 took 249.856s\n",
      "  training loss (in-iteration):\t\t0.769688\n",
      "  train accuracy:\t\t83.25 %\n",
      "  validation accuracy:\t\t82.40 %\n",
      "Epoch 9 of 82 took 250.281s\n",
      "  training loss (in-iteration):\t\t0.733195\n",
      "  train accuracy:\t\t84.41 %\n",
      "  validation accuracy:\t\t83.26 %\n",
      "Epoch 10 of 82 took 250.215s\n",
      "  training loss (in-iteration):\t\t0.710210\n",
      "  train accuracy:\t\t85.17 %\n",
      "  validation accuracy:\t\t83.63 %\n",
      "Epoch 11 of 82 took 249.960s\n",
      "  training loss (in-iteration):\t\t0.690625\n",
      "  train accuracy:\t\t85.89 %\n",
      "  validation accuracy:\t\t83.40 %\n",
      "Epoch 12 of 82 took 250.856s\n",
      "  training loss (in-iteration):\t\t0.675852\n",
      "  train accuracy:\t\t86.48 %\n",
      "  validation accuracy:\t\t85.03 %\n",
      "Epoch 13 of 82 took 251.347s\n",
      "  training loss (in-iteration):\t\t0.660870\n",
      "  train accuracy:\t\t87.10 %\n",
      "  validation accuracy:\t\t84.60 %\n",
      "Epoch 14 of 82 took 251.016s\n",
      "  training loss (in-iteration):\t\t0.651507\n",
      "  train accuracy:\t\t87.49 %\n",
      "  validation accuracy:\t\t85.51 %\n",
      "Epoch 15 of 82 took 250.952s\n",
      "  training loss (in-iteration):\t\t0.642861\n",
      "  train accuracy:\t\t87.89 %\n",
      "  validation accuracy:\t\t85.30 %\n",
      "Epoch 16 of 82 took 250.984s\n",
      "  training loss (in-iteration):\t\t0.631179\n",
      "  train accuracy:\t\t88.41 %\n",
      "  validation accuracy:\t\t85.87 %\n",
      "Epoch 17 of 82 took 250.828s\n",
      "  training loss (in-iteration):\t\t0.622159\n",
      "  train accuracy:\t\t88.85 %\n",
      "  validation accuracy:\t\t84.96 %\n",
      "Epoch 18 of 82 took 250.424s\n",
      "  training loss (in-iteration):\t\t0.619123\n",
      "  train accuracy:\t\t88.84 %\n",
      "  validation accuracy:\t\t86.24 %\n",
      "Epoch 19 of 82 took 251.328s\n",
      "  training loss (in-iteration):\t\t0.616226\n",
      "  train accuracy:\t\t89.11 %\n",
      "  validation accuracy:\t\t86.43 %\n",
      "Epoch 20 of 82 took 250.844s\n",
      "  training loss (in-iteration):\t\t0.608581\n",
      "  train accuracy:\t\t89.46 %\n",
      "  validation accuracy:\t\t86.44 %\n",
      "Epoch 21 of 82 took 250.776s\n",
      "  training loss (in-iteration):\t\t0.608974\n",
      "  train accuracy:\t\t89.47 %\n",
      "  validation accuracy:\t\t86.15 %\n",
      "Epoch 22 of 82 took 251.607s\n",
      "  training loss (in-iteration):\t\t0.601390\n",
      "  train accuracy:\t\t89.84 %\n",
      "  validation accuracy:\t\t86.62 %\n",
      "Epoch 23 of 82 took 251.206s\n",
      "  training loss (in-iteration):\t\t0.600554\n",
      "  train accuracy:\t\t90.02 %\n",
      "  validation accuracy:\t\t86.49 %\n",
      "Epoch 24 of 82 took 250.565s\n",
      "  training loss (in-iteration):\t\t0.596927\n",
      "  train accuracy:\t\t90.13 %\n",
      "  validation accuracy:\t\t87.82 %\n",
      "Epoch 25 of 82 took 251.214s\n",
      "  training loss (in-iteration):\t\t0.594539\n",
      "  train accuracy:\t\t90.20 %\n",
      "  validation accuracy:\t\t87.58 %\n",
      "Epoch 26 of 82 took 251.201s\n",
      "  training loss (in-iteration):\t\t0.592354\n",
      "  train accuracy:\t\t90.33 %\n",
      "  validation accuracy:\t\t87.59 %\n",
      "Epoch 27 of 82 took 251.243s\n",
      "  training loss (in-iteration):\t\t0.584192\n",
      "  train accuracy:\t\t90.68 %\n",
      "  validation accuracy:\t\t87.10 %\n",
      "Epoch 28 of 82 took 251.178s\n",
      "  training loss (in-iteration):\t\t0.591179\n",
      "  train accuracy:\t\t90.43 %\n",
      "  validation accuracy:\t\t87.97 %\n",
      "Epoch 29 of 82 took 250.261s\n",
      "  training loss (in-iteration):\t\t0.582747\n",
      "  train accuracy:\t\t90.80 %\n",
      "  validation accuracy:\t\t86.91 %\n",
      "Epoch 30 of 82 took 251.107s\n",
      "  training loss (in-iteration):\t\t0.584992\n",
      "  train accuracy:\t\t90.68 %\n",
      "  validation accuracy:\t\t88.06 %\n",
      "Epoch 31 of 82 took 250.691s\n",
      "  training loss (in-iteration):\t\t0.579158\n",
      "  train accuracy:\t\t90.91 %\n",
      "  validation accuracy:\t\t87.82 %\n",
      "Epoch 32 of 82 took 250.477s\n",
      "  training loss (in-iteration):\t\t0.580395\n",
      "  train accuracy:\t\t90.89 %\n",
      "  validation accuracy:\t\t88.02 %\n",
      "Epoch 33 of 82 took 250.784s\n",
      "  training loss (in-iteration):\t\t0.581149\n",
      "  train accuracy:\t\t90.94 %\n",
      "  validation accuracy:\t\t87.24 %\n",
      "Epoch 34 of 82 took 250.723s\n",
      "  training loss (in-iteration):\t\t0.581603\n",
      "  train accuracy:\t\t90.93 %\n",
      "  validation accuracy:\t\t88.51 %\n",
      "Epoch 35 of 82 took 250.315s\n",
      "  training loss (in-iteration):\t\t0.571991\n",
      "  train accuracy:\t\t91.28 %\n",
      "  validation accuracy:\t\t88.25 %\n",
      "Epoch 36 of 82 took 250.867s\n",
      "  training loss (in-iteration):\t\t0.579153\n",
      "  train accuracy:\t\t91.06 %\n",
      "  validation accuracy:\t\t86.89 %\n",
      "Epoch 37 of 82 took 250.648s\n",
      "  training loss (in-iteration):\t\t0.580158\n",
      "  train accuracy:\t\t91.08 %\n",
      "  validation accuracy:\t\t87.54 %\n",
      "Epoch 38 of 82 took 250.717s\n",
      "  training loss (in-iteration):\t\t0.575960\n",
      "  train accuracy:\t\t91.23 %\n",
      "  validation accuracy:\t\t87.73 %\n",
      "Epoch 39 of 82 took 250.657s\n",
      "  training loss (in-iteration):\t\t0.572362\n",
      "  train accuracy:\t\t91.35 %\n",
      "  validation accuracy:\t\t87.81 %\n",
      "Epoch 40 of 82 took 251.038s\n",
      "  training loss (in-iteration):\t\t0.572583\n",
      "  train accuracy:\t\t91.44 %\n",
      "  validation accuracy:\t\t88.70 %\n",
      "Epoch 41 of 82 took 250.997s\n",
      "  training loss (in-iteration):\t\t0.449224\n",
      "  train accuracy:\t\t95.75 %\n",
      "  validation accuracy:\t\t91.75 %\n",
      "Epoch 42 of 82 took 251.010s\n",
      "  training loss (in-iteration):\t\t0.398629\n",
      "  train accuracy:\t\t97.17 %\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 43 of 82 took 250.888s\n",
      "  training loss (in-iteration):\t\t0.375201\n",
      "  train accuracy:\t\t97.71 %\n",
      "  validation accuracy:\t\t91.92 %\n",
      "Epoch 44 of 82 took 250.863s\n",
      "  training loss (in-iteration):\t\t0.358046\n",
      "  train accuracy:\t\t98.06 %\n",
      "  validation accuracy:\t\t92.09 %\n",
      "Epoch 45 of 82 took 250.585s\n",
      "  training loss (in-iteration):\t\t0.343239\n",
      "  train accuracy:\t\t98.27 %\n",
      "  validation accuracy:\t\t92.28 %\n",
      "Epoch 46 of 82 took 250.093s\n",
      "  training loss (in-iteration):\t\t0.328320\n",
      "  train accuracy:\t\t98.52 %\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 47 of 82 took 249.826s\n",
      "  training loss (in-iteration):\t\t0.315896\n",
      "  train accuracy:\t\t98.72 %\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 48 of 82 took 249.747s\n",
      "  training loss (in-iteration):\t\t0.305100\n",
      "  train accuracy:\t\t98.84 %\n",
      "  validation accuracy:\t\t92.25 %\n",
      "Epoch 49 of 82 took 249.829s\n",
      "  training loss (in-iteration):\t\t0.295370\n",
      "  train accuracy:\t\t98.92 %\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 50 of 82 took 250.022s\n",
      "  training loss (in-iteration):\t\t0.285254\n",
      "  train accuracy:\t\t99.07 %\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 51 of 82 took 249.906s\n",
      "  training loss (in-iteration):\t\t0.277066\n",
      "  train accuracy:\t\t99.18 %\n",
      "  validation accuracy:\t\t92.27 %\n",
      "Epoch 52 of 82 took 249.936s\n",
      "  training loss (in-iteration):\t\t0.269972\n",
      "  train accuracy:\t\t99.15 %\n",
      "  validation accuracy:\t\t91.99 %\n",
      "Epoch 53 of 82 took 249.774s\n",
      "  training loss (in-iteration):\t\t0.262506\n",
      "  train accuracy:\t\t99.22 %\n",
      "  validation accuracy:\t\t92.00 %\n",
      "Epoch 54 of 82 took 249.974s\n",
      "  training loss (in-iteration):\t\t0.253269\n",
      "  train accuracy:\t\t99.38 %\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 55 of 82 took 249.675s\n",
      "  training loss (in-iteration):\t\t0.247959\n",
      "  train accuracy:\t\t99.31 %\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 56 of 82 took 249.769s\n",
      "  training loss (in-iteration):\t\t0.240560\n",
      "  train accuracy:\t\t99.37 %\n",
      "  validation accuracy:\t\t92.07 %\n",
      "Epoch 57 of 82 took 249.745s\n",
      "  training loss (in-iteration):\t\t0.235368\n",
      "  train accuracy:\t\t99.40 %\n",
      "  validation accuracy:\t\t92.12 %\n",
      "Epoch 58 of 82 took 249.827s\n",
      "  training loss (in-iteration):\t\t0.229374\n",
      "  train accuracy:\t\t99.41 %\n",
      "  validation accuracy:\t\t91.95 %\n",
      "Epoch 59 of 82 took 249.568s\n",
      "  training loss (in-iteration):\t\t0.223631\n",
      "  train accuracy:\t\t99.45 %\n",
      "  validation accuracy:\t\t91.85 %\n",
      "Epoch 60 of 82 took 249.679s\n",
      "  training loss (in-iteration):\t\t0.218314\n",
      "  train accuracy:\t\t99.45 %\n",
      "  validation accuracy:\t\t91.49 %\n",
      "Epoch 61 of 82 took 249.753s\n",
      "  training loss (in-iteration):\t\t0.211145\n",
      "  train accuracy:\t\t99.61 %\n",
      "  validation accuracy:\t\t92.03 %\n",
      "Epoch 62 of 82 took 249.957s\n",
      "  training loss (in-iteration):\t\t0.208258\n",
      "  train accuracy:\t\t99.71 %\n",
      "  validation accuracy:\t\t92.08 %\n",
      "Epoch 63 of 82 took 249.567s\n",
      "  training loss (in-iteration):\t\t0.206614\n",
      "  train accuracy:\t\t99.78 %\n",
      "  validation accuracy:\t\t92.04 %\n",
      "Epoch 64 of 82 took 249.626s\n",
      "  training loss (in-iteration):\t\t0.205126\n",
      "  train accuracy:\t\t99.79 %\n",
      "  validation accuracy:\t\t92.17 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 of 82 took 249.629s\n",
      "  training loss (in-iteration):\t\t0.204260\n",
      "  train accuracy:\t\t99.80 %\n",
      "  validation accuracy:\t\t92.22 %\n",
      "Epoch 66 of 82 took 249.752s\n",
      "  training loss (in-iteration):\t\t0.203390\n",
      "  train accuracy:\t\t99.81 %\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 67 of 82 took 249.565s\n",
      "  training loss (in-iteration):\t\t0.202578\n",
      "  train accuracy:\t\t99.83 %\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Epoch 68 of 82 took 249.826s\n",
      "  training loss (in-iteration):\t\t0.201781\n",
      "  train accuracy:\t\t99.84 %\n",
      "  validation accuracy:\t\t92.24 %\n",
      "Epoch 69 of 82 took 249.824s\n",
      "  training loss (in-iteration):\t\t0.201148\n",
      "  train accuracy:\t\t99.83 %\n",
      "  validation accuracy:\t\t92.24 %\n",
      "Epoch 70 of 82 took 249.729s\n",
      "  training loss (in-iteration):\t\t0.200518\n",
      "  train accuracy:\t\t99.84 %\n",
      "  validation accuracy:\t\t92.16 %\n",
      "Epoch 71 of 82 took 249.653s\n",
      "  training loss (in-iteration):\t\t0.199521\n",
      "  train accuracy:\t\t99.85 %\n",
      "  validation accuracy:\t\t92.25 %\n",
      "Epoch 72 of 82 took 249.821s\n",
      "  training loss (in-iteration):\t\t0.199035\n",
      "  train accuracy:\t\t99.82 %\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 73 of 82 took 249.811s\n",
      "  training loss (in-iteration):\t\t0.198158\n",
      "  train accuracy:\t\t99.87 %\n",
      "  validation accuracy:\t\t92.22 %\n",
      "Epoch 74 of 82 took 250.854s\n",
      "  training loss (in-iteration):\t\t0.197245\n",
      "  train accuracy:\t\t99.87 %\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 75 of 82 took 250.697s\n",
      "  training loss (in-iteration):\t\t0.196865\n",
      "  train accuracy:\t\t99.86 %\n",
      "  validation accuracy:\t\t92.18 %\n",
      "Epoch 76 of 82 took 250.896s\n",
      "  training loss (in-iteration):\t\t0.196337\n",
      "  train accuracy:\t\t99.86 %\n",
      "  validation accuracy:\t\t92.15 %\n",
      "Epoch 77 of 82 took 250.481s\n",
      "  training loss (in-iteration):\t\t0.195531\n",
      "  train accuracy:\t\t99.85 %\n",
      "  validation accuracy:\t\t92.14 %\n",
      "Epoch 78 of 82 took 250.740s\n",
      "  training loss (in-iteration):\t\t0.194802\n",
      "  train accuracy:\t\t99.88 %\n",
      "  validation accuracy:\t\t92.17 %\n",
      "Epoch 79 of 82 took 250.338s\n",
      "  training loss (in-iteration):\t\t0.194054\n",
      "  train accuracy:\t\t99.87 %\n",
      "  validation accuracy:\t\t92.31 %\n",
      "Epoch 80 of 82 took 250.536s\n",
      "  training loss (in-iteration):\t\t0.193794\n",
      "  train accuracy:\t\t99.87 %\n",
      "  validation accuracy:\t\t92.29 %\n",
      "Epoch 81 of 82 took 250.717s\n",
      "  training loss (in-iteration):\t\t0.192842\n",
      "  train accuracy:\t\t99.90 %\n",
      "  validation accuracy:\t\t92.24 %\n",
      "Epoch 82 of 82 took 250.742s\n",
      "  training loss (in-iteration):\t\t0.192569\n",
      "  train accuracy:\t\t99.89 %\n",
      "  validation accuracy:\t\t92.08 %\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "batch_size = 128 #размер мини-батча\n",
    "\n",
    "num_epochs = 82 #количество проходов по данным\n",
    "\n",
    "with open('log-try-2.txt', 'w') as f:\n",
    "    f.write('LR_SCHEDULE: {}\\n'.format(LR_SCHEDULE.__repr__()))\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    if epoch in LR_SCHEDULE:\n",
    "            l_r.set_value(LR_SCHEDULE[epoch])\n",
    "            \n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size,shuffle=True, augment=True):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))\n",
    "    with open('log-try-2.txt', 'a+') as f:\n",
    "        f.write(\"Epoch {} of {} took {:.3f}s\\n\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        f.write(\"  training loss (in-iteration):\\t\\t{:.6f}\\n\".format(train_err / train_batches))\n",
    "        f.write(\"  train accuracy:\\t\\t{:.2f} %\\n\".format(train_acc / train_batches * 100))\n",
    "        f.write(\"  validation accuracy:\\t\\t{:.2f} %\\n\".format(val_acc / val_batches * 100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t92.42 %\n",
      "Нужно больше магии!\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 92.5:\n",
    "    print \"Achievement unlocked: колдун 80 уровня\"\n",
    "else:\n",
    "    print \"Нужно больше магии!\"\n",
    "    \n",
    "\n",
    "with open('log-try-2', 'a+') as f:\n",
    "    f.write(\"Final results:\\n\")\n",
    "    f.write(\"  test accuracy:\\t\\t{:.2f} %\\n\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "\n",
    "    if test_acc / test_batches * 100 > 92.5:\n",
    "        f.write(\"Achievement unlocked: колдун 80 уровня\\n\")\n",
    "    else:\n",
    "        f.write(\"Нужно больше магии!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = lasagne.layers.get_output(net, deterministic=True)\n",
    "test_accuracy = lasagne.objectives.categorical_accuracy(test_prediction, target_y).mean()\n",
    "test_accuracy_fun = theano.function([input_X,target_y],test_accuracy, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t92.37 %\n",
      "Нужно больше магии!\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = test_accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 92.5:\n",
    "    print \"Achievement unlocked: колдун 80 уровня\"\n",
    "else:\n",
    "    print \"Нужно больше магии!\"\n",
    "    \n",
    "\n",
    "with open('log-try-2', 'a+') as f:\n",
    "    f.write(\"Final results:\\n\")\n",
    "    f.write(\"  test accuracy:\\t\\t{:.2f} %\\n\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "\n",
    "    if test_acc / test_batches * 100 > 92.5:\n",
    "        f.write(\"Achievement unlocked: колдун 80 уровня\\n\")\n",
    "    else:\n",
    "        f.write(\"Нужно больше магии!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam_train_fun = theano.function([input_X,target_y],[loss, accuracy], \n",
    "                            updates=lasagne.updates.adam(loss, all_weights, \n",
    "                                                        learning_rate=0.000001),\n",
    "                            allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss (in-iteration):\t\t0.192249\n",
      "  train accuracy:\t\t99.87 %\n"
     ]
    }
   ],
   "source": [
    "train_err = 0\n",
    "train_acc = 0\n",
    "train_batches = 0\n",
    "# In each epoch, we do a full pass over the training data:\n",
    "for batch in iterate_minibatches(X_train, y_train,batch_size,shuffle=True, augment=True):\n",
    "    inputs, targets = batch\n",
    "    train_err_batch, train_acc_batch= adam_train_fun(inputs, targets)\n",
    "    train_err += train_err_batch\n",
    "    train_acc += train_acc_batch\n",
    "    train_batches += 1\n",
    "print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t93.04 %\n",
      "Achievement unlocked: колдун 80 уровня\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = test_accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 92.5:\n",
    "    print \"Achievement unlocked: колдун 80 уровня\"\n",
    "else:\n",
    "    print \"Нужно больше магии!\"\n",
    "    \n",
    "\n",
    "with open('log-try-2', 'a+') as f:\n",
    "    f.write(\"Final results:\\n\")\n",
    "    f.write(\"  test accuracy:\\t\\t{:.2f} %\\n\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "\n",
    "    if test_acc / test_batches * 100 > 92.5:\n",
    "        f.write(\"Achievement unlocked: колдун 80 уровня\\n\")\n",
    "    else:\n",
    "        f.write(\"Нужно больше магии!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заполните форму\n",
    "\n",
    "https://goo.gl/forms/EeadABISlVmdJqgr2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
